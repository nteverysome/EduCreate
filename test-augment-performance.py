#!/usr/bin/env python3
"""
æ¸¬è©¦ Augment æ•ˆèƒ½æå‡çš„å¯¦éš›æ•ˆæœ
"""

import sqlite3
import os
import json
import time
import psutil
from pathlib import Path

def check_databases():
    """æª¢æŸ¥å¢å¼·æ•¸æ“šåº«ç‹€æ…‹"""
    
    print("ğŸ” æª¢æŸ¥ Augment å¢å¼·æ•¸æ“šåº«...")
    
    results = {}
    
    # æª¢æŸ¥ä»£ç¢¼åˆ†ææ•¸æ“šåº«
    if os.path.exists('augment_analysis.db'):
        conn = sqlite3.connect('augment_analysis.db')
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM code_analysis")
        analysis_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM code_patterns")
        patterns_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM dependencies")
        deps_count = cursor.fetchone()[0]
        
        results['code_analysis'] = {
            'status': 'âœ… å¯ç”¨',
            'analyzed_files': analysis_count,
            'patterns_found': patterns_count,
            'dependencies': deps_count
        }
        
        conn.close()
        print(f"âœ… ä»£ç¢¼åˆ†ææ•¸æ“šåº«: {analysis_count} å€‹æª”æ¡ˆå·²åˆ†æ")
    else:
        results['code_analysis'] = {'status': 'âŒ ä¸å­˜åœ¨'}
        print("âŒ ä»£ç¢¼åˆ†ææ•¸æ“šåº«ä¸å­˜åœ¨")
    
    # æª¢æŸ¥å‘é‡æ•¸æ“šåº«
    if os.path.exists('augment_vectors.db'):
        conn = sqlite3.connect('augment_vectors.db')
        cursor = conn.cursor()
        
        try:
            cursor.execute("SELECT COUNT(*) FROM file_vectors")
            vector_count = cursor.fetchone()[0]
            
            results['vector_search'] = {
                'status': 'âœ… å¯ç”¨',
                'indexed_files': vector_count
            }
            print(f"âœ… å‘é‡æœç´¢æ•¸æ“šåº«: {vector_count} å€‹æª”æ¡ˆå·²ç´¢å¼•")
        except:
            results['vector_search'] = {'status': 'âš ï¸ è¡¨çµæ§‹å•é¡Œ'}
            print("âš ï¸ å‘é‡æœç´¢æ•¸æ“šåº«å­˜åœ¨ä½†è¡¨çµæ§‹æœ‰å•é¡Œ")
        
        conn.close()
    else:
        results['vector_search'] = {'status': 'âŒ ä¸å­˜åœ¨'}
        print("âŒ å‘é‡æœç´¢æ•¸æ“šåº«ä¸å­˜åœ¨")
    
    # æª¢æŸ¥è¨˜æ†¶ç³»çµ±
    memory_dir = Path("augment_memory_data")
    if memory_dir.exists():
        memories_file = memory_dir / "memories.json"
        preferences_file = memory_dir / "preferences.json"
        knowledge_file = memory_dir / "knowledge.json"
        
        memory_count = 0
        if memories_file.exists():
            with open(memories_file, 'r', encoding='utf-8') as f:
                memories = json.load(f)
                memory_count = len(memories)
        
        results['memory_system'] = {
            'status': 'âœ… å¯ç”¨',
            'memories_count': memory_count,
            'has_preferences': preferences_file.exists(),
            'has_knowledge': knowledge_file.exists()
        }
        print(f"âœ… è¨˜æ†¶ç³»çµ±: {memory_count} æ¢è¨˜æ†¶")
    else:
        results['memory_system'] = {'status': 'âŒ ä¸å­˜åœ¨'}
        print("âŒ è¨˜æ†¶ç³»çµ±ä¸å­˜åœ¨")
    
    return results

def test_system_performance():
    """æ¸¬è©¦ç³»çµ±æ€§èƒ½"""
    
    print("\nğŸ“Š æ¸¬è©¦ç³»çµ±æ€§èƒ½...")
    
    # CPU ä¿¡æ¯
    cpu_count = psutil.cpu_count()
    cpu_percent = psutil.cpu_percent(interval=1)
    
    # è¨˜æ†¶é«”ä¿¡æ¯
    memory = psutil.virtual_memory()
    memory_gb = memory.total / (1024**3)
    memory_used_percent = memory.percent
    
    # ç£ç¢Ÿä¿¡æ¯
    disk = psutil.disk_usage('.')
    disk_free_gb = disk.free / (1024**3)
    
    performance = {
        'cpu': {
            'cores': cpu_count,
            'usage_percent': cpu_percent
        },
        'memory': {
            'total_gb': round(memory_gb, 1),
            'used_percent': memory_used_percent,
            'available_gb': round(memory.available / (1024**3), 1)
        },
        'disk': {
            'free_gb': round(disk_free_gb, 1)
        }
    }
    
    print(f"ğŸ–¥ï¸ CPU: {cpu_count} æ ¸å¿ƒ, ä½¿ç”¨ç‡ {cpu_percent}%")
    print(f"ğŸ’¾ è¨˜æ†¶é«”: {performance['memory']['total_gb']}GB ç¸½é‡, {memory_used_percent}% å·²ä½¿ç”¨")
    print(f"ğŸ’¿ ç£ç¢Ÿ: {performance['disk']['free_gb']}GB å¯ç”¨ç©ºé–“")
    
    return performance

def test_code_analysis_speed():
    """æ¸¬è©¦ä»£ç¢¼åˆ†æé€Ÿåº¦"""
    
    print("\nâš¡ æ¸¬è©¦ä»£ç¢¼åˆ†æé€Ÿåº¦...")
    
    # æ‰¾ä¸€äº›æ¸¬è©¦æª”æ¡ˆ
    test_files = []
    for ext in ['*.py', '*.js', '*.ts', '*.tsx', '*.json']:
        test_files.extend(list(Path('.').glob(ext)))
    
    if not test_files:
        print("âš ï¸ æ‰¾ä¸åˆ°æ¸¬è©¦æª”æ¡ˆ")
        return None
    
    # é¸æ“‡å‰ 5 å€‹æª”æ¡ˆé€²è¡Œæ¸¬è©¦
    test_files = test_files[:5]
    
    start_time = time.time()
    
    # æ¨¡æ“¬åˆ†æéç¨‹ (è®€å–æª”æ¡ˆå…§å®¹)
    analyzed_files = 0
    total_lines = 0
    
    for file_path in test_files:
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = len(f.readlines())
                total_lines += lines
                analyzed_files += 1
        except:
            continue
    
    end_time = time.time()
    analysis_time = end_time - start_time
    
    result = {
        'files_analyzed': analyzed_files,
        'total_lines': total_lines,
        'analysis_time': round(analysis_time, 3),
        'files_per_second': round(analyzed_files / analysis_time, 2) if analysis_time > 0 else 0,
        'lines_per_second': round(total_lines / analysis_time, 2) if analysis_time > 0 else 0
    }
    
    print(f"ğŸ“ åˆ†æäº† {analyzed_files} å€‹æª”æ¡ˆ")
    print(f"ğŸ“„ ç¸½å…± {total_lines} è¡Œä»£ç¢¼")
    print(f"â±ï¸ ç”¨æ™‚ {analysis_time} ç§’")
    print(f"ğŸš€ é€Ÿåº¦: {result['files_per_second']} æª”æ¡ˆ/ç§’, {result['lines_per_second']} è¡Œ/ç§’")
    
    return result

def test_search_capabilities():
    """æ¸¬è©¦æœç´¢èƒ½åŠ›"""
    
    print("\nğŸ” æ¸¬è©¦æœç´¢èƒ½åŠ›...")
    
    # æ¸¬è©¦æª”æ¡ˆæœç´¢
    search_terms = ['function', 'class', 'import', 'export', 'const']
    search_results = {}
    
    for term in search_terms:
        start_time = time.time()
        
        # åœ¨æ‰€æœ‰ Python å’Œ JavaScript æª”æ¡ˆä¸­æœç´¢
        matches = 0
        files_searched = 0
        
        for ext in ['*.py', '*.js', '*.ts', '*.tsx']:
            for file_path in Path('.').glob(ext):
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                        if term in content:
                            matches += content.count(term)
                        files_searched += 1
                except:
                    continue
        
        search_time = time.time() - start_time
        
        search_results[term] = {
            'matches': matches,
            'files_searched': files_searched,
            'search_time': round(search_time, 3)
        }
    
    print("ğŸ” æœç´¢çµæœ:")
    for term, result in search_results.items():
        print(f"   '{term}': {result['matches']} æ¬¡åŒ¹é…, {result['search_time']} ç§’")
    
    return search_results

def generate_performance_report():
    """ç”Ÿæˆæ€§èƒ½å ±å‘Š"""
    
    print("\nğŸ“‹ ç”Ÿæˆ Augment æ•ˆèƒ½æ¸¬è©¦å ±å‘Š...")
    
    # æ”¶é›†æ‰€æœ‰æ¸¬è©¦çµæœ
    db_status = check_databases()
    system_perf = test_system_performance()
    analysis_speed = test_code_analysis_speed()
    search_results = test_search_capabilities()
    
    # ç”Ÿæˆå ±å‘Š
    report = {
        'test_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
        'database_status': db_status,
        'system_performance': system_perf,
        'code_analysis_speed': analysis_speed,
        'search_capabilities': search_results,
        'summary': {
            'databases_working': sum(1 for db in db_status.values() if 'âœ…' in db.get('status', '')),
            'total_databases': len(db_status),
            'system_health': 'good' if system_perf['memory']['used_percent'] < 80 else 'warning'
        }
    }
    
    # ä¿å­˜å ±å‘Š
    with open('augment_performance_report.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print("âœ… æ€§èƒ½å ±å‘Šå·²ä¿å­˜åˆ° augment_performance_report.json")
    
    return report

def main():
    """ä¸»å‡½æ•¸"""
    
    print("ğŸ¯ Augment æ•ˆèƒ½æå‡å¯¦éš›æ¸¬è©¦")
    print("=" * 50)
    
    # ç”Ÿæˆå®Œæ•´å ±å‘Š
    report = generate_performance_report()
    
    print("\nğŸ“Š æ¸¬è©¦ç¸½çµ:")
    print(f"   æ•¸æ“šåº«ç‹€æ…‹: {report['summary']['databases_working']}/{report['summary']['total_databases']} æ­£å¸¸")
    print(f"   ç³»çµ±å¥åº·: {report['summary']['system_health']}")
    
    if report['code_analysis_speed']:
        print(f"   åˆ†æé€Ÿåº¦: {report['code_analysis_speed']['files_per_second']} æª”æ¡ˆ/ç§’")
    
    print(f"\nğŸ“ è©³ç´°å ±å‘Š: augment_performance_report.json")

if __name__ == "__main__":
    main()
