é–‹å§‹å¾…å®Œæˆä»»å‹™ # å…è²» TTS æ–¹æ¡ˆï¼šåƒå­—æ–‡ç« èªéŸ³æœ—è®€

## ğŸ“‹ æ–‡æª”æ¦‚è¿°

**å‰µå»ºæ—¥æœŸ**: 2025-10-23  
**ç›®çš„**: æä¾›å®Œå…¨å…è²»çš„æ–¹æ¡ˆä¾†å¯¦ç¾åƒå­—æ–‡ç« çš„èªéŸ³æœ—è®€  
**çµè«–**: æœ‰å¤šç¨®å…è²»æ–¹æ¡ˆå¯é¸ï¼Œç„¡éœ€ä»»ä½•æˆæœ¬

---

## ğŸ†“ å®Œå…¨å…è²»çš„ TTS æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: **Web Speech API**ï¼ˆæ¨è–¦ â­â­â­â­â­ï¼‰

#### æŠ€è¡“ç´°ç¯€
é€™æ˜¯ç€è¦½å™¨åŸç”Ÿæ”¯æ´çš„ APIï¼Œå®Œå…¨å…è²»ï¼Œç„¡éœ€ä»»ä½•å¾Œç«¯æœå‹™ã€‚

#### å®Œæ•´å¯¦æ–½ä»£ç¢¼

```html
<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
  <title>åƒå­—æ–‡ç« èªéŸ³æœ—è®€</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 800px;
      margin: 50px auto;
      padding: 20px;
    }
    
    textarea {
      width: 100%;
      height: 300px;
      padding: 10px;
      font-size: 16px;
      border: 2px solid #ddd;
      border-radius: 8px;
      margin-bottom: 20px;
    }
    
    .controls {
      display: flex;
      gap: 10px;
      margin-bottom: 20px;
    }
    
    button {
      padding: 12px 24px;
      font-size: 16px;
      border: none;
      border-radius: 8px;
      cursor: pointer;
      transition: all 0.3s;
    }
    
    .play-btn {
      background-color: #4CAF50;
      color: white;
    }
    
    .play-btn:hover {
      background-color: #45a049;
    }
    
    .pause-btn {
      background-color: #ff9800;
      color: white;
    }
    
    .stop-btn {
      background-color: #f44336;
      color: white;
    }
    
    .settings {
      background-color: #f5f5f5;
      padding: 20px;
      border-radius: 8px;
      margin-bottom: 20px;
    }
    
    .setting-group {
      margin-bottom: 15px;
    }
    
    label {
      display: block;
      margin-bottom: 5px;
      font-weight: bold;
    }
    
    select, input[type="range"] {
      width: 100%;
      padding: 8px;
      font-size: 14px;
    }
    
    .progress {
      margin-top: 20px;
      padding: 10px;
      background-color: #e3f2fd;
      border-radius: 8px;
    }
  </style>
</head>
<body>
  <h1>ğŸ”Š åƒå­—æ–‡ç« èªéŸ³æœ—è®€å™¨</h1>
  
  <div class="settings">
    <h3>èªéŸ³è¨­ç½®</h3>
    
    <div class="setting-group">
      <label for="voiceSelect">é¸æ“‡èªéŸ³ï¼š</label>
      <select id="voiceSelect"></select>
    </div>
    
    <div class="setting-group">
      <label for="rateRange">èªé€Ÿï¼š<span id="rateValue">1.0</span></label>
      <input type="range" id="rateRange" min="0.5" max="2.0" step="0.1" value="1.0">
    </div>
    
    <div class="setting-group">
      <label for="pitchRange">éŸ³èª¿ï¼š<span id="pitchValue">1.0</span></label>
      <input type="range" id="pitchRange" min="0.5" max="2.0" step="0.1" value="1.0">
    </div>
    
    <div class="setting-group">
      <label for="volumeRange">éŸ³é‡ï¼š<span id="volumeValue">1.0</span></label>
      <input type="range" id="volumeRange" min="0" max="1" step="0.1" value="1.0">
    </div>
  </div>
  
  <textarea id="textInput" placeholder="åœ¨æ­¤è¼¸å…¥æ‚¨çš„åƒå­—æ–‡ç« ...">
é€™æ˜¯ä¸€å€‹æ¸¬è©¦æ–‡ç« ã€‚Web Speech API æ˜¯ç€è¦½å™¨åŸç”Ÿæ”¯æ´çš„èªéŸ³åˆæˆæŠ€è¡“ï¼Œå®Œå…¨å…è²»ä¸”ç„¡éœ€ä»»ä½•å¾Œç«¯æœå‹™ã€‚

å®ƒæ”¯æ´å¤šç¨®èªè¨€ï¼ŒåŒ…æ‹¬ç¹é«”ä¸­æ–‡ã€ç°¡é«”ä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ç­‰ã€‚æ‚¨å¯ä»¥èª¿æ•´èªé€Ÿã€éŸ³èª¿å’ŒéŸ³é‡ä¾†ç²å¾—æœ€ä½³çš„æœ—è®€æ•ˆæœã€‚

é€™å€‹æ–¹æ¡ˆç‰¹åˆ¥é©åˆæ•™è‚²æ‡‰ç”¨ï¼Œå› ç‚ºå®ƒä¸éœ€è¦ä»»ä½•æˆæœ¬ï¼Œè€Œä¸”å¯ä»¥å³æ™‚ç”ŸæˆèªéŸ³ï¼Œéå¸¸é©åˆç”¨æ–¼èª²æ–‡æœ—è®€ã€å–®å­—ç™¼éŸ³ç­‰å ´æ™¯ã€‚
  </textarea>
  
  <div class="controls">
    <button class="play-btn" onclick="speakText()">â–¶ï¸ æ’­æ”¾</button>
    <button class="pause-btn" onclick="pauseSpeech()">â¸ï¸ æš«åœ</button>
    <button class="stop-btn" onclick="stopSpeech()">â¹ï¸ åœæ­¢</button>
  </div>
  
  <div class="progress" id="progress">
    æº–å‚™å°±ç·’
  </div>

  <script>
    let synth = window.speechSynthesis;
    let voices = [];
    let currentUtterance = null;
    
    // è¼‰å…¥å¯ç”¨èªéŸ³
    function loadVoices() {
      voices = synth.getVoices();
      const voiceSelect = document.getElementById('voiceSelect');
      voiceSelect.innerHTML = '';
      
      // å„ªå…ˆé¡¯ç¤ºä¸­æ–‡èªéŸ³
      const chineseVoices = voices.filter(voice => 
        voice.lang.includes('zh') || voice.lang.includes('cmn')
      );
      
      const otherVoices = voices.filter(voice => 
        !voice.lang.includes('zh') && !voice.lang.includes('cmn')
      );
      
      // æ·»åŠ ä¸­æ–‡èªéŸ³
      if (chineseVoices.length > 0) {
        const chineseGroup = document.createElement('optgroup');
        chineseGroup.label = 'ä¸­æ–‡èªéŸ³';
        chineseVoices.forEach((voice, index) => {
          const option = document.createElement('option');
          option.value = index;
          option.textContent = `${voice.name} (${voice.lang})`;
          chineseGroup.appendChild(option);
        });
        voiceSelect.appendChild(chineseGroup);
      }
      
      // æ·»åŠ å…¶ä»–èªéŸ³
      if (otherVoices.length > 0) {
        const otherGroup = document.createElement('optgroup');
        otherGroup.label = 'å…¶ä»–èªéŸ³';
        otherVoices.forEach((voice, index) => {
          const option = document.createElement('option');
          option.value = chineseVoices.length + index;
          option.textContent = `${voice.name} (${voice.lang})`;
          otherGroup.appendChild(option);
        });
        voiceSelect.appendChild(otherGroup);
      }
    }
    
    // åˆå§‹åŒ–èªéŸ³åˆ—è¡¨
    loadVoices();
    if (synth.onvoiceschanged !== undefined) {
      synth.onvoiceschanged = loadVoices;
    }
    
    // æ›´æ–°æ»‘æ¡¿é¡¯ç¤ºå€¼
    document.getElementById('rateRange').addEventListener('input', (e) => {
      document.getElementById('rateValue').textContent = e.target.value;
    });
    
    document.getElementById('pitchRange').addEventListener('input', (e) => {
      document.getElementById('pitchValue').textContent = e.target.value;
    });
    
    document.getElementById('volumeRange').addEventListener('input', (e) => {
      document.getElementById('volumeValue').textContent = e.target.value;
    });
    
    // æ’­æ”¾æ–‡å­—
    function speakText() {
      const text = document.getElementById('textInput').value;
      
      if (!text.trim()) {
        alert('è«‹è¼¸å…¥è¦æœ—è®€çš„æ–‡å­—');
        return;
      }
      
      // åœæ­¢ç•¶å‰æ’­æ”¾
      synth.cancel();
      
      // å‰µå»ºæ–°çš„èªéŸ³å¯¦ä¾‹
      currentUtterance = new SpeechSynthesisUtterance(text);
      
      // è¨­ç½®èªéŸ³åƒæ•¸
      const voiceIndex = document.getElementById('voiceSelect').value;
      currentUtterance.voice = voices[voiceIndex];
      currentUtterance.rate = parseFloat(document.getElementById('rateRange').value);
      currentUtterance.pitch = parseFloat(document.getElementById('pitchRange').value);
      currentUtterance.volume = parseFloat(document.getElementById('volumeRange').value);
      
      // äº‹ä»¶ç›£è½
      currentUtterance.onstart = () => {
        document.getElementById('progress').textContent = 'æ­£åœ¨æ’­æ”¾...';
        document.getElementById('progress').style.backgroundColor = '#c8e6c9';
      };
      
      currentUtterance.onend = () => {
        document.getElementById('progress').textContent = 'æ’­æ”¾å®Œæˆ';
        document.getElementById('progress').style.backgroundColor = '#e3f2fd';
      };
      
      currentUtterance.onerror = (event) => {
        document.getElementById('progress').textContent = `éŒ¯èª¤: ${event.error}`;
        document.getElementById('progress').style.backgroundColor = '#ffcdd2';
      };
      
      // é–‹å§‹æ’­æ”¾
      synth.speak(currentUtterance);
    }
    
    // æš«åœæ’­æ”¾
    function pauseSpeech() {
      if (synth.speaking && !synth.paused) {
        synth.pause();
        document.getElementById('progress').textContent = 'å·²æš«åœ';
        document.getElementById('progress').style.backgroundColor = '#fff9c4';
      } else if (synth.paused) {
        synth.resume();
        document.getElementById('progress').textContent = 'ç¹¼çºŒæ’­æ”¾...';
        document.getElementById('progress').style.backgroundColor = '#c8e6c9';
      }
    }
    
    // åœæ­¢æ’­æ”¾
    function stopSpeech() {
      synth.cancel();
      document.getElementById('progress').textContent = 'å·²åœæ­¢';
      document.getElementById('progress').style.backgroundColor = '#e3f2fd';
    }
  </script>
</body>
</html>
```

#### å„ªé»
âœ… **å®Œå…¨å…è²»**ï¼Œç„¡ä»»ä½•æˆæœ¬  
âœ… **ç„¡éœ€å¾Œç«¯æœå‹™**ï¼Œç´”å‰ç«¯å¯¦ç¾  
âœ… **æ”¯æ´å¤šç¨®èªè¨€**ï¼ˆç¹é«”ä¸­æ–‡ã€ç°¡é«”ä¸­æ–‡ã€è‹±æ–‡ç­‰ï¼‰  
âœ… **å¯èª¿æ•´èªé€Ÿã€éŸ³èª¿ã€éŸ³é‡**  
âœ… **å³æ™‚ç”Ÿæˆ**ï¼Œç„¡å»¶é²  
âœ… **æ”¯æ´æš«åœ/ç¹¼çºŒ**  
âœ… **ç„¡å­—æ•¸é™åˆ¶**ï¼ˆå¯ä»¥æœ—è®€åƒå­—ä»¥ä¸Šçš„æ–‡ç« ï¼‰

#### ç¼ºé»
âŒ èªéŸ³è³ªé‡å–æ±ºæ–¼æ“ä½œç³»çµ±å’Œç€è¦½å™¨  
âŒ ä¸åŒè¨­å‚™çš„èªéŸ³å¯èƒ½ä¸ä¸€è‡´  
âŒ ç„¡æ³•ä¿å­˜ç‚ºéŸ³é »æ–‡ä»¶ï¼ˆåªèƒ½å³æ™‚æ’­æ”¾ï¼‰

#### ç€è¦½å™¨æ”¯æ´
- âœ… Chrome/Edge: å®Œå…¨æ”¯æ´
- âœ… Safari: å®Œå…¨æ”¯æ´
- âœ… Firefox: å®Œå…¨æ”¯æ´
- âœ… Opera: å®Œå…¨æ”¯æ´

---

### æ–¹æ¡ˆ 2: **åˆ†æ®µæœ—è®€ + å…è²» TTS API**

å¦‚æœæ‚¨éœ€è¦æ›´é«˜è³ªé‡çš„èªéŸ³ï¼Œå¯ä»¥ä½¿ç”¨å…è²»é¡åº¦çš„å•†æ¥­ TTS æœå‹™ã€‚

#### Google Cloud TTSï¼ˆæ¯æœˆ 100 è¬å­—ç¬¦å…è²»ï¼‰

```javascript
// Node.js å¾Œç«¯ç¯„ä¾‹
const textToSpeech = require('@google-cloud/text-to-speech');
const fs = require('fs');

const client = new textToSpeech.TextToSpeechClient();

async function generateSpeechForLongText(text, outputFile) {
  // åˆ†æ®µè™•ç†ï¼ˆæ¯æ®µ 5000 å­—ç¬¦ï¼‰
  const maxChars = 5000;
  const segments = [];
  
  for (let i = 0; i < text.length; i += maxChars) {
    segments.push(text.substring(i, i + maxChars));
  }
  
  const audioSegments = [];
  
  for (const segment of segments) {
    const request = {
      input: { text: segment },
      voice: { 
        languageCode: 'zh-TW',
        name: 'zh-TW-Wavenet-A'
      },
      audioConfig: { audioEncoding: 'MP3' }
    };
    
    const [response] = await client.synthesizeSpeech(request);
    audioSegments.push(response.audioContent);
  }
  
  // åˆä½µéŸ³é »ç‰‡æ®µ
  const combinedAudio = Buffer.concat(audioSegments);
  fs.writeFileSync(outputFile, combinedAudio, 'binary');
  
  console.log(`éŸ³é »å·²ä¿å­˜åˆ° ${outputFile}`);
}

// ä½¿ç”¨ç¯„ä¾‹
const longText = `æ‚¨çš„åƒå­—æ–‡ç« å…§å®¹...`;
generateSpeechForLongText(longText, 'output.mp3');
```

#### æˆæœ¬åˆ†æ
- **å…è²»é¡åº¦**: æ¯æœˆ 100 è¬å­—ç¬¦
- **åƒå­—æ–‡ç« **: ç´„ 1,000 å­—ç¬¦
- **å¯å…è²»ç”Ÿæˆ**: æ¯æœˆ 1,000 ç¯‡åƒå­—æ–‡ç« 
- **è¶…å‡ºå¾Œ**: $16 USD / 100 è¬å­—ç¬¦

---

### æ–¹æ¡ˆ 3: **Coqui TTSï¼ˆé–‹æºè‡ªå»ºï¼‰**

å®Œå…¨å…è²»çš„é–‹æº TTS è§£æ±ºæ–¹æ¡ˆï¼Œé©åˆè‡ªå·±éƒ¨ç½²ã€‚

#### å®‰è£å’Œä½¿ç”¨

```bash
# å®‰è£ Coqui TTS
pip install TTS

# åˆ—å‡ºå¯ç”¨æ¨¡å‹
tts --list_models

# ç”ŸæˆèªéŸ³ï¼ˆä¸­æ–‡ï¼‰
tts --text "æ‚¨çš„åƒå­—æ–‡ç« å…§å®¹" \
    --model_name "tts_models/zh-CN/baker/tacotron2-DDC-GST" \
    --out_path output.wav
```

#### Python è…³æœ¬ç¯„ä¾‹

```python
from TTS.api import TTS
import os

# åˆå§‹åŒ– TTS æ¨¡å‹
tts = TTS(model_name="tts_models/zh-CN/baker/tacotron2-DDC-GST")

def generate_speech_for_long_text(text, output_file):
    """
    ç‚ºé•·æ–‡æœ¬ç”ŸæˆèªéŸ³
    """
    # åˆ†æ®µè™•ç†ï¼ˆæ¯æ®µ 500 å­—ç¬¦ï¼‰
    max_chars = 500
    segments = [text[i:i+max_chars] for i in range(0, len(text), max_chars)]
    
    temp_files = []
    
    # ç‚ºæ¯æ®µç”ŸæˆéŸ³é »
    for i, segment in enumerate(segments):
        temp_file = f"temp_segment_{i}.wav"
        tts.tts_to_file(text=segment, file_path=temp_file)
        temp_files.append(temp_file)
    
    # ä½¿ç”¨ pydub åˆä½µéŸ³é »ç‰‡æ®µ
    from pydub import AudioSegment
    
    combined = AudioSegment.empty()
    for temp_file in temp_files:
        audio = AudioSegment.from_wav(temp_file)
        combined += audio
        os.remove(temp_file)  # åˆªé™¤è‡¨æ™‚æ–‡ä»¶
    
    # å°å‡ºæœ€çµ‚éŸ³é »
    combined.export(output_file, format="mp3")
    print(f"éŸ³é »å·²ä¿å­˜åˆ° {output_file}")

# ä½¿ç”¨ç¯„ä¾‹
long_text = """
æ‚¨çš„åƒå­—æ–‡ç« å…§å®¹...
"""

generate_speech_for_long_text(long_text, "output.mp3")
```

#### å„ªé»
âœ… **å®Œå…¨å…è²»**  
âœ… **å¯ä»¥ä¿å­˜ç‚ºéŸ³é »æ–‡ä»¶**  
âœ… **æ”¯æ´å¤šç¨®èªè¨€**  
âœ… **å¯ä»¥è‡ªå®šç¾©å’Œè¨“ç·´æ¨¡å‹**  
âœ… **ç„¡å­—æ•¸é™åˆ¶**

#### ç¼ºé»
âŒ éœ€è¦è‡ªå·±çš„ä¼ºæœå™¨æˆ–æœ¬åœ°é‹è¡Œ  
âŒ éœ€è¦ä¸€å®šçš„æŠ€è¡“èƒ½åŠ›  
âŒ ç”Ÿæˆé€Ÿåº¦è¼ƒæ…¢ï¼ˆå–æ±ºæ–¼ç¡¬ä»¶ï¼‰

---

### æ–¹æ¡ˆ 4: **pyttsx3ï¼ˆé›¢ç·š Python TTSï¼‰**

æœ€ç°¡å–®çš„é›¢ç·š TTS æ–¹æ¡ˆã€‚

#### å®‰è£å’Œä½¿ç”¨

```bash
pip install pyttsx3
```

#### Python è…³æœ¬ç¯„ä¾‹

```python
import pyttsx3

def read_long_text(text, save_to_file=None):
    """
    æœ—è®€é•·æ–‡æœ¬æˆ–ä¿å­˜ç‚ºéŸ³é »æ–‡ä»¶
    """
    engine = pyttsx3.init()
    
    # è¨­ç½®èªéŸ³åƒæ•¸
    engine.setProperty('rate', 150)  # èªé€Ÿ
    engine.setProperty('volume', 1.0)  # éŸ³é‡
    
    # ç²å–å¯ç”¨èªéŸ³
    voices = engine.getProperty('voices')
    
    # å˜—è©¦è¨­ç½®ä¸­æ–‡èªéŸ³
    for voice in voices:
        if 'chinese' in voice.name.lower() or 'mandarin' in voice.name.lower():
            engine.setProperty('voice', voice.id)
            break
    
    if save_to_file:
        # ä¿å­˜ç‚ºæ–‡ä»¶
        engine.save_to_file(text, save_to_file)
        engine.runAndWait()
        print(f"éŸ³é »å·²ä¿å­˜åˆ° {save_to_file}")
    else:
        # å³æ™‚æ’­æ”¾
        engine.say(text)
        engine.runAndWait()

# ä½¿ç”¨ç¯„ä¾‹
long_text = """
æ‚¨çš„åƒå­—æ–‡ç« å…§å®¹...
"""

# å³æ™‚æ’­æ”¾
read_long_text(long_text)

# æˆ–ä¿å­˜ç‚ºæ–‡ä»¶
read_long_text(long_text, save_to_file="output.mp3")
```

#### å„ªé»
âœ… **å®Œå…¨å…è²»**  
âœ… **é›¢ç·šé‹è¡Œ**ï¼Œç„¡éœ€ç¶²çµ¡  
âœ… **ç°¡å–®æ˜“ç”¨**  
âœ… **å¯ä»¥ä¿å­˜ç‚ºéŸ³é »æ–‡ä»¶**  
âœ… **ç„¡å­—æ•¸é™åˆ¶**

#### ç¼ºé»
âŒ èªéŸ³è³ªé‡è¼ƒä½  
âŒ ä¸­æ–‡æ”¯æ´å–æ±ºæ–¼æ“ä½œç³»çµ±

---

## ğŸ“Š æ–¹æ¡ˆå°æ¯”

| æ–¹æ¡ˆ | æˆæœ¬ | èªéŸ³è³ªé‡ | æ˜“ç”¨æ€§ | å¯ä¿å­˜æ–‡ä»¶ | æ¨è–¦åº¦ |
|------|------|---------|--------|-----------|--------|
| **Web Speech API** | $0 | â­â­â­ | â­â­â­â­â­ | âŒ | â­â­â­â­â­ |
| **Google Cloud TTS** | $0ï¼ˆå…è²»é¡åº¦å…§ï¼‰ | â­â­â­â­â­ | â­â­â­â­ | âœ… | â­â­â­â­ |
| **Coqui TTS** | $0 | â­â­â­â­ | â­â­â­ | âœ… | â­â­â­â­ |
| **pyttsx3** | $0 | â­â­ | â­â­â­â­â­ | âœ… | â­â­â­ |

---

## ğŸ¯ æ¨è–¦æ–¹æ¡ˆ

### å¦‚æœæ‚¨éœ€è¦**å³æ™‚æœ—è®€**ï¼ˆä¸éœ€è¦ä¿å­˜æ–‡ä»¶ï¼‰
**æ¨è–¦**: **Web Speech API** â­â­â­â­â­

**ç†ç”±**:
- å®Œå…¨å…è²»
- ç„¡éœ€å¾Œç«¯
- å¯¦æ–½ç°¡å–®
- æ”¯æ´åƒå­—ä»¥ä¸Šçš„æ–‡ç« 

### å¦‚æœæ‚¨éœ€è¦**ä¿å­˜ç‚ºéŸ³é »æ–‡ä»¶**
**æ¨è–¦**: **Google Cloud TTSï¼ˆå…è²»é¡åº¦ï¼‰** â­â­â­â­

**ç†ç”±**:
- æ¯æœˆ 100 è¬å­—ç¬¦å…è²»
- å¯ä»¥ç”Ÿæˆ 1,000 ç¯‡åƒå­—æ–‡ç« 
- èªéŸ³è³ªé‡æœ€é«˜

### å¦‚æœæ‚¨éœ€è¦**å®Œå…¨é›¢ç·š**
**æ¨è–¦**: **Coqui TTS** â­â­â­â­

**ç†ç”±**:
- å®Œå…¨å…è²»
- ç„¡éœ€ç¶²çµ¡
- èªéŸ³è³ªé‡è¼ƒå¥½

---

## ğŸ’¡ å¯¦æ–½å»ºè­°

### æœ€ä½³å¯¦è¸ï¼šæ··åˆæ–¹æ¡ˆ

```javascript
// å‰ç«¯ï¼šä½¿ç”¨ Web Speech API å³æ™‚æ’­æ”¾
function playTextImmediately(text) {
  const utterance = new SpeechSynthesisUtterance(text);
  utterance.lang = 'zh-TW';
  window.speechSynthesis.speak(utterance);
}

// å¾Œç«¯ï¼šä½¿ç”¨ Google Cloud TTS ç”Ÿæˆå¯ä¸‹è¼‰çš„éŸ³é »æ–‡ä»¶
async function generateDownloadableAudio(text) {
  // èª¿ç”¨ Google Cloud TTS API
  const audioUrl = await generateSpeech(text);
  return audioUrl;
}

// ç”¨æˆ¶å¯ä»¥é¸æ“‡ï¼š
// 1. å³æ™‚æ’­æ”¾ï¼ˆå…è²»ï¼ŒWeb Speech APIï¼‰
// 2. ä¸‹è¼‰éŸ³é »ï¼ˆå…è²»é¡åº¦å…§ï¼ŒGoogle Cloud TTSï¼‰
```

---

## ğŸ“š å®Œæ•´ç¯„ä¾‹å°ˆæ¡ˆ

æˆ‘å·²ç¶“åœ¨ä¸Šé¢æä¾›äº†å®Œæ•´çš„ HTML ç¯„ä¾‹ï¼Œæ‚¨å¯ä»¥ç›´æ¥è¤‡è£½ä½¿ç”¨ã€‚é€™å€‹ç¯„ä¾‹åŒ…æ‹¬ï¼š

1. âœ… æ–‡å­—è¼¸å…¥å€åŸŸ
2. âœ… èªéŸ³é¸æ“‡ï¼ˆè‡ªå‹•åµæ¸¬ä¸­æ–‡èªéŸ³ï¼‰
3. âœ… èªé€Ÿã€éŸ³èª¿ã€éŸ³é‡èª¿æ•´
4. âœ… æ’­æ”¾ã€æš«åœã€åœæ­¢æ§åˆ¶
5. âœ… æ’­æ”¾é€²åº¦é¡¯ç¤º
6. âœ… å®Œæ•´çš„éŒ¯èª¤è™•ç†

---

## ğŸ“ ç¸½çµ

**æœ€æ¨è–¦çš„å…è²»æ–¹æ¡ˆ**: **Web Speech API**

**åŸå› **:
- âœ… å®Œå…¨å…è²»ï¼Œç„¡ä»»ä½•æˆæœ¬
- âœ… ç„¡éœ€å¾Œç«¯æœå‹™
- âœ… æ”¯æ´åƒå­—ä»¥ä¸Šçš„æ–‡ç« 
- âœ… å¯¦æ–½ç°¡å–®ï¼Œåªéœ€å‰ç«¯ä»£ç¢¼
- âœ… æ”¯æ´å¤šç¨®èªè¨€
- âœ… å¯èª¿æ•´èªé€Ÿã€éŸ³èª¿ã€éŸ³é‡

**å”¯ä¸€é™åˆ¶**: ç„¡æ³•ä¿å­˜ç‚ºéŸ³é »æ–‡ä»¶ï¼ˆåªèƒ½å³æ™‚æ’­æ”¾ï¼‰

å¦‚æœæ‚¨éœ€è¦ä¿å­˜éŸ³é »æ–‡ä»¶ï¼Œå¯ä»¥ä½¿ç”¨ Google Cloud TTS çš„å…è²»é¡åº¦ï¼ˆæ¯æœˆ 100 è¬å­—ç¬¦ï¼‰ï¼Œè¶³å¤ ç”Ÿæˆ 1,000 ç¯‡åƒå­—æ–‡ç« ã€‚

---

**æ–‡æª”å‰µå»ºæ—¥æœŸ**: 2025-10-23  
**ç¶­è­·è€…**: EduCreate Development Team

